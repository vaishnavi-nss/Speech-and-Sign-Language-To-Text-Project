# ðŸ§  Speech and Sign-to-Text Project

This project combines **Speech-to-Text** and **Sign Language Recognition** using Python, FastAPI, and Machine Learning models. It allows users to upload either an audio file or an image of a hand gesture and get a predicted transcription or sign language label.

---

## ðŸ“‚ Project Structure

| File / Folder       | Description |
|---------------------|-------------|
| `main.py`           | FastAPI app entry point. Integrates both speech and sign language routes. |
| `sign_language.py`  | Endpoint to process sign language gesture images and return predictions. |
| `transcribe.py`     | Endpoint to transcribe audio files into text using Whisper and FFmpeg. |
| `train_model.py`    | Script used to train the sign language recognition model. |
| `models.py`         | Code for loading, saving, and handling ML models. |
| `utils.py`          | Helper functions for preprocessing, file handling, etc. |
| `index.html`        | Simple frontend (optional) to upload files and interact with the API. |
| `README.md`         | Project overview and setup instructions. |

---

## ðŸš€ Features

âœ… Transcribes speech to text using OpenAI Whisper  
âœ… Recognizes hand gestures (sign language) using a trained TensorFlow/Keras model  
âœ… Built with FastAPI for performance and simplicity  
âœ… Easy API access via `/predict/` and `/transcribe/`  
âœ… Model training script included (`train_model.py`)  
âœ… Clean code structure and modular design

---

ðŸ“Œ TODO / Future Enhancements
 Add gesture landmarks using MediaPipe or OpenCV

 Add live webcam capture for gesture detection

 Improve accuracy with more training data

 Frontend dashboard to upload audio/images

 Dockerize the app for deployment
